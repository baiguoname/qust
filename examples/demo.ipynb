{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65fdddb6",
   "metadata": {},
   "source": [
    "# Qust\n",
    "支持流式计算的查询引擎，底层基于rust, 应用层用的python\n",
    "-----\n",
    "* 流式计算，算子有状态保留，支持流式计算\n",
    "* 性能高，大多数情况下速度比polars高，内存消耗更少\n",
    "* 算子丰富，内置丰富的金融算子，比如k线合成、回测、组合优化等等\n",
    "* 可拓展性强，底层基于rust的`datafusion`, 拓展到分布式很方便.\n",
    "\n",
    "[文档地址](https://raw.githack.com/baiguoname/qust/main/examples/docs/qust.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6f3d5",
   "metadata": {},
   "source": [
    "# 安装\n",
    "```python\n",
    "pip install -i https://pypi.tuna.tsinghua.edu.cn/simple qust\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ae388",
   "metadata": {},
   "source": [
    "# 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dc3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qust as qs\n",
    "from qust import col\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fac705",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "data = pl.DataFrame({\n",
    "    \"factor\": np.random.randn(n),\n",
    "    \"code\": np.random.choice([\"a\", \"b\", \"c\"], size=n, replace=True),\n",
    "})\n",
    "data_next = pl.DataFrame({\n",
    "    \"factor\": np.random.randn(n),\n",
    "    \"code\": np.random.choice([\"a\", \"b\", \"c\"], size=n, replace=True),\n",
    "})\n",
    "\n",
    "df = qs.with_cols(\n",
    "    col(\"factor\").mean().expanding().alias(\"cum_mean\"),\n",
    "    col(\"factor\").mean().rolling(3).alias(\"rolling_mean\"),\n",
    "    col(\"factor\").mean().expanding().over(\"code\").alias(\"cum_mean_over\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0665978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 5)\n",
      "┌───────────┬──────┬───────────┬──────────────┬───────────────┐\n",
      "│ factor    ┆ code ┆ cum_mean  ┆ rolling_mean ┆ cum_mean_over │\n",
      "│ ---       ┆ ---  ┆ ---       ┆ ---          ┆ ---           │\n",
      "│ f64       ┆ str  ┆ f64       ┆ f64          ┆ f64           │\n",
      "╞═══════════╪══════╪═══════════╪══════════════╪═══════════════╡\n",
      "│ 0.111683  ┆ c    ┆ 0.111683  ┆ null         ┆ 0.111683      │\n",
      "│ 1.585938  ┆ b    ┆ 0.848811  ┆ null         ┆ 1.585938      │\n",
      "│ -1.154133 ┆ b    ┆ 0.181163  ┆ 0.181163     ┆ 0.215903      │\n",
      "│ -1.311661 ┆ b    ┆ -0.192043 ┆ -0.293285    ┆ -0.293285     │\n",
      "│ 1.56433   ┆ b    ┆ 0.159231  ┆ -0.300488    ┆ 0.171118      │\n",
      "│ -1.293334 ┆ c    ┆ -0.082863 ┆ -0.346889    ┆ -0.590826     │\n",
      "│ -2.050297 ┆ c    ┆ -0.363925 ┆ -0.593101    ┆ -1.077316     │\n",
      "│ -0.891518 ┆ b    ┆ -0.429874 ┆ -1.411717    ┆ -0.041409     │\n",
      "│ 0.378405  ┆ c    ┆ -0.340065 ┆ -0.85447     ┆ -0.713386     │\n",
      "│ -0.341524 ┆ b    ┆ -0.340211 ┆ -0.284879    ┆ -0.091428     │\n",
      "└───────────┴──────┴───────────┴──────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.calc_data(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9caa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 5)\n",
      "┌───────────┬──────┬───────────┬──────────────┬───────────────┐\n",
      "│ factor    ┆ code ┆ cum_mean  ┆ rolling_mean ┆ cum_mean_over │\n",
      "│ ---       ┆ ---  ┆ ---       ┆ ---          ┆ ---           │\n",
      "│ f64       ┆ str  ┆ f64       ┆ f64          ┆ f64           │\n",
      "╞═══════════╪══════╪═══════════╪══════════════╪═══════════════╡\n",
      "│ -0.643198 ┆ c    ┆ -0.367756 ┆ -0.202106    ┆ -0.699348     │\n",
      "│ -0.097377 ┆ b    ┆ -0.345224 ┆ -0.3607      ┆ -0.092278     │\n",
      "│ 2.340298  ┆ c    ┆ -0.138645 ┆ 0.533241     ┆ -0.192741     │\n",
      "│ 0.269679  ┆ b    ┆ -0.109479 ┆ 0.837533     ┆ -0.047033     │\n",
      "│ 1.169616  ┆ b    ┆ -0.024206 ┆ 1.259864     ┆ 0.08815       │\n",
      "│ 0.303631  ┆ c    ┆ -0.003717 ┆ 0.580975     ┆ -0.12183      │\n",
      "│ 0.404867  ┆ b    ┆ 0.020318  ┆ 0.626038     ┆ 0.119821      │\n",
      "│ 1.007454  ┆ c    ┆ 0.075159  ┆ 0.571984     ┆ 0.01933       │\n",
      "│ 0.51271   ┆ b    ┆ 0.098188  ┆ 0.641677     ┆ 0.155539      │\n",
      "│ 1.670847  ┆ b    ┆ 0.176821  ┆ 1.06367      ┆ 0.281814      │\n",
      "└───────────┴──────┴───────────┴──────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.calc_data(data_next)) # df 里面的算子都状态保留"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb851f",
   "metadata": {},
   "source": [
    "# 与polars语法比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64a38fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>price</th><th>code</th><th>cum_sum_otters</th><th>cum_sum_polars</th><th>cum_sum_otters_over</th><th>cum_sum_polars_over</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;a&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>&quot;a&quot;</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>2</td><td>&quot;a&quot;</td><td>3</td><td>3</td><td>3</td><td>3</td></tr><tr><td>3</td><td>&quot;b&quot;</td><td>6</td><td>6</td><td>3</td><td>3</td></tr><tr><td>4</td><td>&quot;b&quot;</td><td>10</td><td>10</td><td>7</td><td>7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌───────┬──────┬────────────────┬────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ price ┆ code ┆ cum_sum_otters ┆ cum_sum_polars ┆ cum_sum_otters_over ┆ cum_sum_polars_over │\n",
       "│ ---   ┆ ---  ┆ ---            ┆ ---            ┆ ---                 ┆ ---                 │\n",
       "│ i64   ┆ str  ┆ i64            ┆ i64            ┆ i64                 ┆ i64                 │\n",
       "╞═══════╪══════╪════════════════╪════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 0     ┆ a    ┆ 0              ┆ 0              ┆ 0                   ┆ 0                   │\n",
       "│ 1     ┆ a    ┆ 1              ┆ 1              ┆ 1                   ┆ 1                   │\n",
       "│ 2     ┆ a    ┆ 3              ┆ 3              ┆ 3                   ┆ 3                   │\n",
       "│ 3     ┆ b    ┆ 6              ┆ 6              ┆ 3                   ┆ 3                   │\n",
       "│ 4     ┆ b    ┆ 10             ┆ 10             ┆ 7                   ┆ 7                   │\n",
       "└───────┴──────┴────────────────┴────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.DataFrame({\n",
    "    \"price\": range(5),\n",
    "    \"code\": [\"a\", \"a\", \"a\", \"b\", \"b\"]\n",
    "})\n",
    "df = qs.with_cols(\n",
    "    col(\"price\").sum().expanding().alias(\"cum_sum_otters\"),\n",
    "    pl.col(\"price\").cum_sum().alias(\"cum_sum_polars\"),\n",
    "    col(\"price\").sum().expanding().over(\"code\").alias(\"cum_sum_otters_over\"),\n",
    "    pl.col(\"price\").cum_sum().over(\"code\").alias(\"cum_sum_polars_over\")\n",
    ")\n",
    "df.calc_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d3eaa",
   "metadata": {},
   "source": [
    "# 与polars性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "382a71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "n = 2000000\n",
    "data = pl.DataFrame({\n",
    "    \"factor\": np.random.randn(n),\n",
    "    \"code\": np.random.choice([\"a\", \"b\"], size=n, replace=True),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe90091",
   "metadata": {},
   "source": [
    "### 1. qust单线程 vs polars多线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c62a5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qust: 100.04281997680664.ms\n",
      "polars: 157.47618675231934.ms\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "_ = qs.select(\n",
    "    col(\"factor\").rank().rolling(10).over(\"code\")\n",
    ").calc_data(data)\n",
    "print(f\"qust: {(time.time() - s) * 1000.0}.ms\")\n",
    "\n",
    "s = time.time()\n",
    "_ = data.select(\n",
    "    pl.col(\"factor\").rolling_rank(10).over(\"code\")\n",
    ")\n",
    "print(f\"polars: {(time.time() - s) * 1000.0}.ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b51e0b",
   "metadata": {},
   "source": [
    "### 2. qust多线程 vs polars多线程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12410952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qust: 112.96653747558594.ms\n",
      "polars: 298.112154006958.ms\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "_ = qs.select(\n",
    "    col(*[col(\"factor\").mean().alias(f\"mean_{i}\") for i in range(50)]).rolling(10).over(\"code\")\n",
    ").calc_data(data)\n",
    "print(f\"qust: {(time.time() - s) * 1000.0}.ms\")\n",
    "\n",
    "s = time.time()\n",
    "_ = data.select(\n",
    "    [pl.col(\"factor\").rolling_mean(10).over(\"code\").alias(f\"mean_{i}\") for i in range(50)]\n",
    ")\n",
    "print(f\"polars: {(time.time() - s) * 1000.0}.ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6eff2d",
   "metadata": {},
   "source": [
    "### 3. qust自定义算子 vs polars自定义算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2f739798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qust: 1.298762321472168.s\n",
      "polars: 53.331793785095215.s\n"
     ]
    }
   ],
   "source": [
    "class MeanUdf(qs.UdfRow):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sum = 0.0\n",
    "        self.count = 0.0\n",
    "\n",
    "    def output_schema(self, input_schema):\n",
    "        return [(\"mean_res\", pl.Float64)]\n",
    "    \n",
    "    def update(self, value):\n",
    "        self.sum += value\n",
    "        self.count += 1.0\n",
    "\n",
    "    def calc(self):\n",
    "        return [self.sum / self.count]\n",
    "\n",
    "    def retract(self, value):\n",
    "        self.sum -= value\n",
    "        self.count -= 1.0\n",
    "\n",
    "s = time.time()\n",
    "_ = qs.select(\n",
    "    col(\"factor\").udf.row(MeanUdf()).rolling(10).over(\"code\")\n",
    ").calc_data(data)\n",
    "print(f\"qust: {(time.time() - s)}.s\")\n",
    "\n",
    "s = time.time()\n",
    "_ = data.select(\n",
    "    pl.col(\"factor\").rolling_map(lambda x: x.mean(), 10).over(\"code\")\n",
    ")\n",
    "print(f\"polars: {(time.time() - s)}.s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458ce60",
   "metadata": {},
   "source": [
    ">--------\n",
    "| 算子 | qust | polars | 提速 |\n",
    "|----|------|-------------|---|\n",
    "| 单个算子 | 100ms | 157ms | 1.5倍 |\n",
    "| 多个算子 | 110ms | 290ms | 2.5倍 |\n",
    "| 自定义rolling算子 | 1.5s | 53s | 40倍 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1444d96",
   "metadata": {},
   "source": [
    "# 为什么有polars，还要写qust？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6913dca",
   "metadata": {},
   "source": [
    "### 1. 流式计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80362052",
   "metadata": {},
   "source": [
    "写量化策略的时候，一般有下面两种方法\n",
    "\n",
    "1. 向量化计算\n",
    "\n",
    "2. 事件驱动\n",
    "\n",
    "如果策略用向量化计算，在实盘的时候就很慢，因为要重复计算历史数据, 而且很多策略没法向量化\n",
    "\n",
    "如果策略用的事件驱动，回测的时候就很慢，而且事件驱动写法特别麻烦\n",
    "\n",
    "流计算就是把算子都写成事件驱动的形式。比如计算移动平均，在算子里面存储两个状态 `(sum, count)`, 每有一个行新数据`value`过来，更新算子的内部状态:\n",
    "\n",
    "`sum = sum + value`\n",
    "\n",
    "`count = count + 1`\n",
    "\n",
    "在需要计算结果的时候就用  `sum / count`\n",
    "\n",
    "```python\n",
    "data = pl.DataFrame({\n",
    "    \"value\": [1, 2, 3, 4, 5]\n",
    "})\n",
    "data_next = pl.DataFrame({\n",
    "    \"value\": [6, 7, 8]\n",
    "})\n",
    "\n",
    "df = qs.with_cols(\n",
    "    col(\"value\").mean().rolling(3).alias(\"rolling_mean\"),\n",
    "    col(\"value\").std().expanding().alias(\"cum_std\"),\n",
    ")\n",
    "\n",
    "print(df.calc_data(data))\n",
    "shape: (5, 3)\n",
    "┌───────┬──────────────┬──────────┐\n",
    "│ value ┆ rolling_mean ┆ cum_std  │\n",
    "│ ---   ┆ ---          ┆ ---      │\n",
    "│ i64   ┆ f64          ┆ f64      │\n",
    "╞═══════╪══════════════╪══════════╡\n",
    "│ 1     ┆ null         ┆ null     │\n",
    "│ 2     ┆ null         ┆ 0.707107 │\n",
    "│ 3     ┆ 2.0          ┆ 1.0      │\n",
    "│ 4     ┆ 3.0          ┆ 1.290994 │\n",
    "│ 5     ┆ 4.0          ┆ 1.581139 │\n",
    "└───────┴──────────────┴──────────┘\n",
    "print(df.calc_data(data_next))\n",
    "shape: (3, 3)\n",
    "┌───────┬──────────────┬──────────┐\n",
    "│ value ┆ rolling_mean ┆ cum_std  │\n",
    "│ ---   ┆ ---          ┆ ---      │\n",
    "│ i64   ┆ f64          ┆ f64      │\n",
    "╞═══════╪══════════════╪══════════╡\n",
    "│ 6     ┆ 5.0          ┆ 1.870829 │\n",
    "│ 7     ┆ 6.0          ┆ 2.160247 │\n",
    "│ 8     ┆ 7.0          ┆ 2.44949  │\n",
    "└───────┴──────────────┴──────────┘\n",
    "```\n",
    "在第一个调用`df.calc_data(data)`的时候，df内部的算子都有状态保留，所以在第二个调用`df.calc_data(data_next)`时候，没有重新计算\n",
    "\n",
    "实际情况是，绝大多数算子都有对应的事件驱动形式，少量的算子比如`pl.col(\"a\").rank()`, 看起来不是事件驱动的形式（当前行的值受到未来行的值的影响），但是其实也可以变换成事件驱动形式，\n",
    "* 转换成行算子，比如 a 列有a1，a2，a3三个元素，就是`col(a1, a2, a3).rank(axis=1)` \n",
    "\n",
    "* 事件驱动形式的批算子，每次计算的时候保证传入的数据完整，比如计算`pl.col(\"a\").rank().over(\"date\")`, 保证每次计算传入的数据包含整天的所有数据\n",
    "\n",
    "`polars`不是也支持streaming吗？我看了polars的底层，觉得polars的streaming不是真正意义上的流式计算，只是为了避免out of memory，而且局限性大(比如`over`是用的 切割 -> 计算 -> 拼接)。如果polars要实现真正的流式计算，我估计底层得推倒重来改成`datafusion`的那种框架\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc691e0",
   "metadata": {},
   "source": [
    "### 2. 表达式解耦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507ca9e",
   "metadata": {},
   "source": [
    "`polars`的`Expr`用的`enum`, 这样就导致每实现一个算子，底层很多代码都要改, 这样就不难理解为什么一个简单的`pl.col(\"a\").rolling_rank(10)`算子直到最近才实现，而且速度比我一个简单的实现慢一倍。\n",
    "\n",
    "`datafusion`聚合算子用的`Box<dyn trait>`, 然后根据上下文选择不同路径的`ExecutionPlan`, 这样添加算子很方便，而且优化路径也很清晰，性能还不受影响。\n",
    "\n",
    "`polars`这种写法还有个缺点，就是导致同样的逻辑写法割裂，比如求和逻辑有下面写法:\n",
    "* `pl.col(\"a\").sum()`\n",
    "\n",
    "* `pl.col(\"a\").cum_sum()`\n",
    "\n",
    "* `pl.col(\"a\").rolling_sum(10)`\n",
    "\n",
    "* `df.group_by(\"b\").agg([pl.col(\"a\").sum()])`\n",
    "\n",
    "如果说 `sum()` 和 `rolling_sum(10)`, 都是求和逻辑, 前一个是针对整列，后一个是针对滚动，但是 `rank()`和`rolling_rank(10)`, 又是两个不想关的算子, 而且并不存在`cum_rank()`这个算子，这样逻辑就很割裂，为什么能存在`cum_sum`, 但是不能存在`cum_rank`, `cum_skew`, `cum_cov`? \n",
    "\n",
    "相反用`datafusion`的上下文逻辑，写法就比较一致:\n",
    "* `col(\"a\").sum()`\n",
    "\n",
    "* `col(\"a\").sum().expanding()`\n",
    "\n",
    "* `col(\"a\").sum().rolling(10)`\n",
    "\n",
    "* `col(\"a\").sum().group_by(\"b\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286b159",
   "metadata": {},
   "source": [
    "### 3. 多列返回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199e5f7",
   "metadata": {},
   "source": [
    "`polars` 和 `datafusion` 对单个算子都不支持多列返回，但是`datafusion`提供了插件接口，能改成多列返回:\n",
    "```python\n",
    "n = 7\n",
    "data = pl.DataFrame({\n",
    "    \"y\": np.random.randn(n),\n",
    "    \"x1\": np.random.randn(n),\n",
    "    \"x2\": np.random.randn(n),\n",
    "})\n",
    "res = qs.with_cols(\n",
    "    col(\"y\", \"x1\", \"x2\").stock.ols().rolling(4).add_suffix(\"rolling_beta\"),\n",
    ").calc_data(data)\n",
    "print(res)\n",
    "shape: (7, 5)\n",
    "┌───────────┬───────────┬───────────┬─────────────────┬─────────────────┐\n",
    "│ y         ┆ x1        ┆ x2        ┆ x1_rolling_beta ┆ x2_rolling_beta │\n",
    "│ ---       ┆ ---       ┆ ---       ┆ ---             ┆ ---             │\n",
    "│ f64       ┆ f64       ┆ f64       ┆ f64             ┆ f64             │\n",
    "╞═══════════╪═══════════╪═══════════╪═════════════════╪═════════════════╡\n",
    "│ 0.522261  ┆ -0.376497 ┆ -0.594123 ┆ null            ┆ null            │\n",
    "│ 1.325991  ┆ -0.723979 ┆ 2.626444  ┆ null            ┆ null            │\n",
    "│ 1.502309  ┆ -2.089571 ┆ 0.28167   ┆ null            ┆ null            │\n",
    "│ -0.322316 ┆ 0.00877   ┆ -0.213895 ┆ -0.731707       ┆ 0.271784        │\n",
    "│ -0.733964 ┆ -0.750248 ┆ -0.592936 ┆ -0.47639        ┆ 0.465733        │\n",
    "│ 0.445435  ┆ -0.559213 ┆ -0.44069  ┆ -0.56446        ┆ 1.174467        │\n",
    "│ 1.735427  ┆ -2.403888 ┆ 1.207053  ┆ -0.29973        ┆ 0.849167        │\n",
    "└───────────┴───────────┴───────────┴─────────────────┴─────────────────┘\n",
    "```\n",
    "多列返回我能想到以下好处\n",
    "* 多列返回在用一些比如k线合成算子，策略信号算子之类的比较方便\n",
    "\n",
    "* 另一个是避免用`struct`, 如果底层依赖从`arror-rs`改成[`MinArrow`](https://github.com/pbower/minarrow), 估计内存占用能到原来的一半，并且耗时减少"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0e05e",
   "metadata": {},
   "source": [
    "### 4. `datafusion` 功能更齐全，比如:\n",
    "* 支持`DataFrame` Api 和 sql相互转换，`polars`不行\n",
    "\n",
    "* 原生支持`arrow`, `datafusion`是`arrow`的一部分，未来生态会更丰富, `polars`自己写了一个`polars-arrow`, 生态割裂\n",
    "\n",
    "* `datafusion` 有成熟的分布式应用，而且全部开源，`polars` 前期是基于`datafusion`的二次开发，目前分布式刚起步，而且闭源，貌似已经**把主要精力放在商业闭源上面去了**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5a950",
   "metadata": {},
   "source": [
    ">--------\n",
    "`qust`是用`rust`写的一个`datafusion`插件，主要目的是尝试用`DataFrame api`去写事件驱动量化策略，并且保持向量化计算的高性能.\n",
    "\n",
    "所以主要是添加一些能够状态保留的算子，其他一些无需状态保留的算子，还是依赖于`polars`的算子，比如:\n",
    "```python\n",
    "col(\"a\") + 1\n",
    "```\n",
    "会报错:\n",
    "```\n",
    "TypeError: unsupported operand type(s) for +: 'Expr' and 'int'\n",
    "```\n",
    "只能用`polars`的算子:\n",
    "```python\n",
    "qs.select(\n",
    "    pl.col(\"a\") + 1,\n",
    "    pl.col(\"a\").rank().over(\"code\")\n",
    "    col(\"a\").select(pl.col(\"a\") + 1).over(\"code\")\n",
    ")\n",
    "```\n",
    "\n",
    "当然，上面说的只是我个人的理解，对这方面有兴趣的朋友可以加我微信交流，微信号: aruster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e5ccd",
   "metadata": {},
   "source": [
    "# 写策略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdef24",
   "metadata": {},
   "source": [
    "### 1. 有k线数据，实现一个双均线策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59fdb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 策略逻辑\n",
    "stra = (\n",
    "    col(\n",
    "        col(\"close\"),\n",
    "        col(\"datetime\"),\n",
    "        col(\"close\").future.two_ma(10, 20), # 通过算子生成信号\n",
    "    )\n",
    "        .with_cols(col(\"cross_up\", \"cross_down\").future.to_hold_always().alias(\"hold\")) # 通过信号生成目标持仓\n",
    ")\n",
    "# 回测\n",
    "df_bt = qs.select(\n",
    "    stra.with_cols(\n",
    "        col(\"close\", \"hold\").future.backtest()\n",
    "    ).expanding().select(\n",
    "        col(\"pnl\").sum().group_by(pl.col(\"datetime\").dt.date().alias(\"date\"))\n",
    "    ).with_cols(\n",
    "        col(\"pnl\").sum().alias(\"pnl_cum\").expanding() \n",
    "    )\n",
    ")\n",
    "\n",
    "# 实盘\n",
    "df_live = qs.select(stra.expanding().select(\"hold\").last_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\"https://github.com/baiguoname/qust/blob/main/examples/data/300_1min_vnpy.parquet?raw=true\") # 从github读取数据，速度较慢\n",
    "# 假设历史数据\n",
    "data_his = data[:600000]\n",
    "# 假设实盘数据流\n",
    "data_live = [data[600000:601000], data[601000:602000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c17b026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_500, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>pnl</th><th>pnl_cum</th></tr><tr><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2009-01-05</td><td>0.01188</td><td>0.01188</td></tr><tr><td>2009-01-06</td><td>-0.001413</td><td>0.010467</td></tr><tr><td>2009-01-07</td><td>0.010793</td><td>0.02126</td></tr><tr><td>2009-01-08</td><td>0.020342</td><td>0.041603</td></tr><tr><td>2009-01-09</td><td>-0.001545</td><td>0.040058</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2019-04-11</td><td>0.007004</td><td>-0.338696</td></tr><tr><td>2019-04-12</td><td>-0.008302</td><td>-0.346997</td></tr><tr><td>2019-04-15</td><td>0.006445</td><td>-0.340553</td></tr><tr><td>2019-04-16</td><td>0.004031</td><td>-0.336522</td></tr><tr><td>2019-04-17</td><td>-0.022107</td><td>-0.358629</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_500, 3)\n",
       "┌────────────┬───────────┬───────────┐\n",
       "│ date       ┆ pnl       ┆ pnl_cum   │\n",
       "│ ---        ┆ ---       ┆ ---       │\n",
       "│ date       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╡\n",
       "│ 2009-01-05 ┆ 0.01188   ┆ 0.01188   │\n",
       "│ 2009-01-06 ┆ -0.001413 ┆ 0.010467  │\n",
       "│ 2009-01-07 ┆ 0.010793  ┆ 0.02126   │\n",
       "│ 2009-01-08 ┆ 0.020342  ┆ 0.041603  │\n",
       "│ 2009-01-09 ┆ -0.001545 ┆ 0.040058  │\n",
       "│ …          ┆ …         ┆ …         │\n",
       "│ 2019-04-11 ┆ 0.007004  ┆ -0.338696 │\n",
       "│ 2019-04-12 ┆ -0.008302 ┆ -0.346997 │\n",
       "│ 2019-04-15 ┆ 0.006445  ┆ -0.340553 │\n",
       "│ 2019-04-16 ┆ 0.004031  ┆ -0.336522 │\n",
       "│ 2019-04-17 ┆ -0.022107 ┆ -0.358629 │\n",
       "└────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 回测\n",
    "df_bt.calc_data(data_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01927c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌──────┐\n",
      "│ hold │\n",
      "│ ---  │\n",
      "│ f64  │\n",
      "╞══════╡\n",
      "│ 1.0  │\n",
      "└──────┘\n",
      "shape: (1, 1)\n",
      "┌──────┐\n",
      "│ hold │\n",
      "│ ---  │\n",
      "│ f64  │\n",
      "╞══════╡\n",
      "│ 1.0  │\n",
      "└──────┘\n"
     ]
    }
   ],
   "source": [
    "# 实盘\n",
    "df_live.calc_data(data_his)\n",
    "for data_live_ in data_live:\n",
    "    print(df_live.calc_data(data_live_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23520fff",
   "metadata": {},
   "source": [
    "### 2. 有数据源，这个数据源不断获取多个品种的tick数据，策略需要分品种将数据不断合成1min k线，并且生成双均线的开仓逻辑，然后用0.01止损作为出场"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f40615c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 策略逻辑\n",
    "col_tick = col(\"t\", \"c\", \"v\", \"bid1\", \"ask1\", \"bid1_v\", \"ask1_v\")\n",
    "stra = (\n",
    "    col(\n",
    "        col(\"c\"),\n",
    "        col(\"t\"),\n",
    "        col_tick.future.kline(qs.KlineType.future_ra1m).with_cols(\n",
    "            col(\"close\").future.two_ma(10, 20).filter_cb(\"is_finished\")\n",
    "        ),\n",
    "    ).with_cols(\n",
    "        col(\n",
    "            col(\"cross_up\", \"c\").future.exit_by_pct(0.01, False).alias(\"take_profit_long\"),\n",
    "            col(\"cross_up\", \"c\").future.exit_by_pct(0.01, True).alias(\"stop_loss_long\"),\n",
    "        )\n",
    "            .with_cols(\n",
    "                (pl.col(\"take_profit_long\") | pl.col(\"stop_loss_long\")).alias(\"exit_long_sig\") \n",
    "            ),\n",
    "        col(\n",
    "            col(\"cross_down\", \"c\").future.exit_by_pct(0.01, True).alias(\"take_profit_short\"),\n",
    "            col(\"cross_down\", \"c\").future.exit_by_pct(0.01, False).alias(\"stop_loss_short\"),\n",
    "        )   \n",
    "            .with_cols(\n",
    "                (pl.col(\"take_profit_short\") | pl.col(\"stop_loss_short\")).alias(\"exit_short_sig\")\n",
    "            )\n",
    "    ).with_cols(\n",
    "        col(\"cross_up\", \"exit_long_sig\", \"cross_down\", \"exit_short_sig\")\n",
    "            .future\n",
    "            .to_hold_two_sides()\n",
    "            .alias(\"hold\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 价格回测\n",
    "df_bt_price = (\n",
    "    qs.select(\n",
    "        stra\n",
    "            .with_cols(\n",
    "                col(\"c\", \"hold\").future.backtest(),\n",
    "            )\n",
    "            .expanding()\n",
    "            .over(\"ticker\")\n",
    "            .select(\n",
    "                col(\"pnl\").sum().group_by(pl.col(\"t\").dt.date().alias(\"date\"))\n",
    "            )\n",
    "            .with_cols(\n",
    "                col(\"pnl\").sum().alias(\"pnl_cum\").expanding()\n",
    "            )\n",
    "    )\n",
    ")\n",
    "\n",
    "# tick回测\n",
    "df_bt_tick = (\n",
    "    qs.select(\n",
    "        col(\n",
    "            \"bid1\",\n",
    "            \"ask1\",\n",
    "            stra,\n",
    "        )\n",
    "            .with_cols(\n",
    "                col(\"hold\", \"c\", \"bid1\", \"ask1\")\n",
    "                    .future\n",
    "                    .backtest_tick(qs.TradePriceType.queue, qs.MatchPriceType.simnow)\n",
    "                    # .backtest_tick(qs.TradePriceType.last_price, qs.MatchPriceType.void)\n",
    "            )\n",
    "            .expanding()\n",
    "            .over(\"ticker\")\n",
    "            .select(\n",
    "                col(\"pnl\").sum().group_by(pl.col(\"t\").dt.date().alias(\"date\"))\n",
    "            )\n",
    "            .with_cols(\n",
    "                col(\"pnl\").sum().alias(\"pnl_cum\").expanding()\n",
    "            )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a08716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\"https://github.com/baiguoname/qust/tree/main/examples/data/tick_data.parquet?raw=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8398adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bt_price.calc_data(data).plot.line(x = \"date\", y = \"pnl_cum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bt_tick.calc_data(data).plot.line(x = \"date\", y = \"pnl_cum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b8cd4",
   "metadata": {},
   "source": [
    "### 3. 一个更复杂的策略，接受tick数据，同时合成5min和30min的k线，双周期共振的均线策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b210b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 策略逻辑\n",
    "col_tick = col(\"t\", \"c\", \"v\", \"bid1\", \"ask1\", \"bid1_v\", \"ask1_v\")\n",
    "stra =  (\n",
    "    col(\n",
    "        col(\"c\"),\n",
    "        col(\"t\"),\n",
    "        col_tick.future.kline(qs.KlineType.rl5m)\n",
    "            .with_cols(\n",
    "                col(\"close\").future.two_ma(10, 20).filter_cb(\"is_finished\")\n",
    "            )\n",
    "            .add_suffix(\"m5\"),\n",
    "        col_tick.future.kline(qs.KlineType.rl30m)\n",
    "            .with_cols(\n",
    "                col(\"close\").future.two_ma(10, 20).filter_cb(\"is_finished\")\n",
    "            )\n",
    "            .add_suffix(\"m30\")\n",
    "    )\n",
    "        .with_cols(\n",
    "            col(\"cross_up_m30\", \"cross_down_m30\").ffill()\n",
    "        )\n",
    "        .with_cols(\n",
    "            col(pl.col(\"cross_up_m5\") & pl.col(\"cross_up_m30\")).alias(\"open_long_sig\"),\n",
    "            col(pl.col(\"cross_down_m5\") & pl.col(\"cross_down_m30\")).alias(\"open_short_sig\"),\n",
    "        )\n",
    "        .with_cols(\n",
    "            col(\n",
    "                col(\"open_long_sig\", \"c\").future.exit_by_pct(0.05, False).alias(\"take_profit_long\"),\n",
    "                col(\"open_long_sig\", \"c\").future.exit_by_pct(0.02, True).alias(\"stop_loss_long\"),\n",
    "            )\n",
    "                .select(\n",
    "                    (pl.col(\"take_profit_long\") | pl.col(\"stop_loss_long\")).alias(\"exit_long_sig\") \n",
    "                ),\n",
    "            col(\n",
    "                col(\"open_short_sig\", \"c\").future.exit_by_pct(0.05, True).alias(\"take_profit_short\"),\n",
    "                col(\"open_short_sig\", \"c\").future.exit_by_pct(0.02, False).alias(\"stop_loss_short\"),\n",
    "            )   \n",
    "                .select(\n",
    "                    (pl.col(\"take_profit_short\") | pl.col(\"stop_loss_short\")).alias(\"exit_short_sig\")\n",
    "                )\n",
    "        )\n",
    "        .with_cols(\n",
    "            col(\"open_long_sig\", \"exit_long_sig\", \"open_short_sig\", \"exit_short_sig\")\n",
    "                .future\n",
    "                .to_hold_two_sides()\n",
    "                .alias(\"hold\")\n",
    "        )\n",
    ")\n",
    "\n",
    "# tick回测逻辑\n",
    "df_bt_tick = (\n",
    "    qs.select(\n",
    "        col(\n",
    "            \"bid1\",\n",
    "            \"ask1\",\n",
    "            stra,\n",
    "        )\n",
    "            .with_cols(\n",
    "                col(\"hold\", \"c\", \"bid1\", \"ask1\")\n",
    "                    .future\n",
    "                    .backtest_tick(qs.TradePriceType.queue, qs.MatchPriceType.simnow)\n",
    "                    # .backtest_tick(qs.TradePriceType.last_price, qs.MatchPriceType.void)\n",
    "            )\n",
    "            .expanding()\n",
    "            .over(\"ticker\")\n",
    "            .select(\n",
    "                col(\"pnl\").sum().group_by(pl.col(\"t\").dt.date().alias(\"date\"))\n",
    "            )\n",
    "            .with_cols(\n",
    "                col(\"pnl\").sum().alias(\"pnl_cum\").expanding()\n",
    "            )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bt_tick.calc_data(data).plot.line(x = \"date\", y = \"pnl_cum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fcb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
